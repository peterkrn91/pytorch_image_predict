{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)  # Input 1x28x28, Output 32x28x28\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # Output 32x14x14\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # Input 32x14x14, Output 64x14x14\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # Output 64x7x7\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)  # Input 64*7*7=3136, Output 512\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 10)  # Input 512, Output 10 (number of classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.act1(self.conv1(x)))\n",
    "        x = self.pool2(self.act2(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # Flatten all dimensions except batch\n",
    "        x = self.act3(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(root=\".\", train=True, download=True, transform=ToTensor())\n",
    "# training_data = datasets.FashionMNIST(root=\".\", train=True, download=True, transform=ToTensor())\n",
    "\n",
    "test_data = datasets.MNIST(root=\".\", train=False, download=True, transform=ToTensor())\n",
    "# test_data = datasets.FashionMNIST(root=\".\", train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Trained Model from Google Colab (5 Epochs, 90% accuracy, T4 GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Trained Model\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = MNISTModel()\n",
    "\n",
    "PATH = 'trained_model_acc_90.pth'\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Image Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 5\n",
      "Output probabilities: [0.00010912139987340197, 1.492532106794897e-07, 0.011908882297575474, 0.06017802283167839, 1.2147648220661722e-08, 0.927375853061676, 2.7306637662150024e-07, 2.6558485842542723e-05, 0.00040040345629677176, 8.415304932896106e-07]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "import torch\n",
    "\n",
    "\n",
    "# Define the normalization transform (if used during training)\n",
    "normalize = Normalize(mean=[0.5], std=[0.5])  # Example normalization for images with pixel values in [0, 1]\n",
    "\n",
    "# Preprocess the test image\n",
    "test_image_path = 'test/paint-5.png'\n",
    "test_image = Image.open(test_image_path).convert('L')  # Convert to grayscale if necessary\n",
    "test_image = test_image.resize((28, 28))  # Resize to match model input size\n",
    "test_image_tensor = ToTensor()(test_image).unsqueeze(0)  # Convert to tensor and add batch dimension\n",
    "\n",
    "# Apply normalization if used during training\n",
    "# test_image_tensor = normalize(test_image_tensor)\n",
    "\n",
    "# Perform prediction\n",
    "with torch.no_grad():\n",
    "    output = model(test_image_tensor)\n",
    "    probabilities = torch.softmax(output, dim=1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "# Display prediction result\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "print(f\"Output probabilities: {probabilities.squeeze().tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Image in Flask Web-App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [13/May/2024 14:40:44] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [13/May/2024 14:40:44] \"GET /static/styles.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [13/May/2024 14:40:44] \"GET /static/index.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [13/May/2024 14:40:46] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [13/May/2024 14:40:51] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [13/May/2024 14:40:51] \"GET /static/styles.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [13/May/2024 14:40:58] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [13/May/2024 14:40:58] \"GET /static/styles.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [13/May/2024 14:41:04] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [13/May/2024 14:41:04] \"GET /static/styles.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [13/May/2024 14:45:07] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [13/May/2024 14:45:07] \"GET /static/styles.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [13/May/2024 14:45:17] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [13/May/2024 14:45:17] \"GET /static/styles.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [13/May/2024 14:45:24] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [13/May/2024 14:45:24] \"GET /static/styles.css HTTP/1.1\" 304 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "from io import BytesIO\n",
    "import torch\n",
    "\n",
    "app = Flask(__name__, template_folder='templates', static_url_path='/static')\n",
    "\n",
    "# Define the normalization transform\n",
    "normalize = Normalize(mean=[0.5], std=[0.5])  # Assuming input pixel range [0, 255]\n",
    "\n",
    "def initialize_flask_app():\n",
    "    # Define route (endpoint) for home page\n",
    "    @app.route('/', methods=['GET'])\n",
    "    def home():\n",
    "        return render_template('index.html')\n",
    "\n",
    "    # Define route (endpoint) for handling image upload and prediction\n",
    "    @app.route('/predict', methods=['POST'])\n",
    "    def predict():\n",
    "        if 'image' in request.files:\n",
    "            # Read and preprocess the uploaded image\n",
    "            img = Image.open(BytesIO(request.files['image'].read()))\n",
    "            img = img.convert('L')  # Convert to grayscale\n",
    "            img = img.resize((28, 28))  # Resize image to 28x28\n",
    "            img = ToTensor()(img).unsqueeze(0)  # Convert to tensor and add batch dimension\n",
    "            img = normalize(img)  # Apply normalization\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(img)\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                prediction = predicted.item()\n",
    "\n",
    "            return render_template('result.html', prediction=prediction)\n",
    "        else:\n",
    "            return 'Error: No image provided.'\n",
    "\n",
    "    # Run the Flask app\n",
    "    if __name__ == '__main__':\n",
    "        app.run()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    initialize_flask_app()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
